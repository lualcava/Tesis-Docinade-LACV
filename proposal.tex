\chapter{Propuesta de Proyecto}
\section{Planteamiento del Problema}
Actualmente es común encontrar bases de datos en las cuales existen instancias o tuplas incompletas, es decir, que contienen valores faltantes en alguno de los atributos. Existen múltiples métodos para la imputación de dichos valores, por ejemplo, los que involucran algoritmos de aprendizaje máquina que se basan en los valores de los atributos completos de la instancia para predecir el valor faltante \cite{tran2015multiple,ishioka2014investigations}.\\
Este proyecto se enfoca en aquellos casos donde los atributos completos son de tipo texto libre y en los cuales la imputación se realiza mediante algún algoritmo de clasificación y aprendizaje supervisado. En este caso, el algoritmo utiliza un conjunto de datos de entrenamiento formado por instancias sin valores faltantes, donde la etiqueta de clase corresponde al valor del atributo que eventualmente se intentará imputar en registros sin dicho valor.\\
El hecho de que los atributos a considerar sean textuales representa varios retos para el algoritmo de clasificación. Métodos típicos de estimación o regresión lineal utilizados para imputación de datos en series de tiempo y atributos numéricos quedan descartados \cite{mavai2014survey}. Además, un texto libre implica una cadena de caracteres con valores no estandarizados \cite{khan2006comparison}. Por ejemplo, si se trata de valores introducidos por usuarios existe la posibilidad de que todas las instancias contengan diferentes valores para el mismo atributo.\\
En compañias grandes, donde se manejan cientos de bases de datos que almacenan información de transacciones generadas diariamente, este escenario resulta común. Por ejemplo, en el 2015, en Intel® se encontró que alrededor del 20\% de los perfiles de usuarios creados en el sitio web de empleos de la compañía, no contaban con un valor para el país de procedencia. Esto representó un grave problema debido a que toda la información de perfiles de candidatos estaba siendo migrada a un nuevo sistema, en el cual el valor del país era requerido.Aunque una persona podría inferir dicho valor basándose en otros atributos como el nombre del candidato, la ciudad, el código postal o la dirección, no se contaba con suficientes recursos para cubrir los casi 200 mil registros con valores faltantes. El hecho de que los atributos completos fueran de tipo texto, libremente introducido por los candidatos al registrarse, representaba un reto computacional y algorítmico si se intentaba automatizar el proceso para imputar el valor del país. Por lo tanto, la decisión tomada consistió en descartar cualquier registro con valores faltantes, ocasionando pérdida de alrededor de un 20\% de los datos durante la migración.\\
En situaciones como esta, la minería de texto juega un papel importante y actualmente se han propuesto diferentes métodos para la clasificación que involucran técnicas de representación de documentos, medidas de similitud léxica y semántica para comparar valores de texto y algoritmos de aprendizaje máquina \cite{wang2016non}. Documentos de texto similares pueden ser agrupados en categorías por el algoritmo de clasificación.\\
Aún existen muchos escenarios, tal como el caso de la base de datos de Intel®, en los que no hay una solucion óptima y por lo tanto, resultan en problemas interesantes de explorar. Por ejemplo, casos en los cuales se cuenta con textos muy cortos donde no existe un contexto ni suficiente información para inferir la semántica, o cuando un mismo texto involucra diferentes tipos de entidades como acciones, nombres propios o fechas que no pueden compararse de la misma manera \cite{hoffart2011robust,metzler2007similarity}.\\
Es precisamente este tipo de problemas el que se pretende atacar en este trabajo, combinando algoritmos de similitud de texto usando métodos agregados, de forma que se mejore la exactitud al momento de imputar un dato faltante basado en clasificación.\\
En la siguiente sección se describe la propuesta general del proyecto a desarrollar.



\section{Propuesta del Proyecto}
Dado el problema planteado anteriormente, el presente proyecto busca crear un nuevo método que mejore la exactitud obtenida como resultado de clasificar documentos de texto. Esto con el fin de lograr un mayor nivel de acierto al imputar valores faltantes bajo las circunstancias descritas en el problema. Para ello, se pretenden estudiar diferentes técnicas de representación de documentos y métricas de similitud de texto como parte de un algoritmo de clasificación de aprendizaje supervisado. De igual manera, se incorporarán métodos agregados para aumentar la robustez y el rendimiento de los algoritmos \cite{sabzevari2015ensemble}. \\
La idea principal consiste en desarrollar un programa capaz de manejar métodos agregados de $bagging$ y $boosting$, con algoritmos de clasificación de documentos que utilicen técnicas de representación y métricas de similitud de texto tradicionales (vector de palabras, similitud coseno, distancia $Jaccard$) y otras no tan comunes como LDA y divergencia KL. La implementación de estos métodos se aplicará sobre conjuntos de datos compuestos por registros de dos atributos: uno de tipo texto y otro de tipo categórico, de forma que el algoritmo pueda inferir la categoría basado en el atributo de texto.\\
Se espera que los resultados obtenidos permitan identificar una estrategia de clasificación, en la cual la utilización de métricas basadas en distribuciones de probabilidad logre una mayor exactitud con respecto a los métodos tradicionales. Los conjuntos de datos a utilizar en los experimentos corresponden principalmente al repositorio Reuters, el cual está formado por conjuntos de documentos de los cuales se pueden extraer diferentes categorías. De igual forma, se hará uso de un subconjunto de los datos de Intel® sobre información personal de candidatos a puestos de trabajo con país de procedencia faltante (ver tabla \ref{table-datasets}). \\ 

\begin{table}[h!]
\centering
\caption{Conjuntos de datos a utilizar en los experimentos}
\label{table-datasets}
\begin{tabular}{|l|l|l|l|l|}
\hline
\rowcolor[HTML]{CBCEFB} 
Conjuntos de datos                                                    & $\sim$Registros & Categoría & $\sim$Valores distintos en categoría & Ejemplo                                                                 \\ \hline
\begin{tabular}[c]{@{}l@{}}reut2-005.sgm\\ reut2-006.sgm\end{tabular} & 1063            & Temas     & 74                                   & \begin{tabular}[c]{@{}l@{}}housing\\ money\\ earn\\ grain\end{tabular}  \\ \hline
\begin{tabular}[c]{@{}l@{}}reut2-003.sgm\\ reut2-004.sgm\end{tabular} & 1641            & Lugares   & 92                                   & \begin{tabular}[c]{@{}l@{}}USA\\ UK\\ Brazil\\ Netherlands\end{tabular} \\ \hline
\begin{tabular}[c]{@{}l@{}}candidates (Intel) \end{tabular} & 500000& País   & 190                                   & \begin{tabular}[c]{@{}l@{}}USA\\ CHN\\ TWN\\ ISR\end{tabular} \\ \hline

\end{tabular}
\end{table}

\section{Trabajos Relacionados}
Actualmente se han propuesto diversos algoritmos en al campo de la minería de datos y del aprendizaje máquina para resolver problemas de valores faltantes mediante clasificación. En el caso del presente proyecto, se busca un clasificador que permita encontrar relaciones entre atributos de tipo texto y atributos de tipo categórico. En esta sección se resume el trabajo realizado por diferentes autores alrededor de estos temas. \\
En \cite{tran2015multiple,truong2004learning, ishioka2014investigations} se habla de varios métodos de clasificación supervisada tales como $hot deck$, KNN y Árboles Aleatorios. Al ser supervisadas, dichas técnicas requieren de un conjunto de datos entrenamiento etiquetado y además se caracterizan por basarse en medidas de similitud que permiten definir las relaciones entre los elementos a clasificar. Existen también algoritmos basados en modelos estadísticos tales como la imputación $likelihood$ (que utiliza la técnica de $Expectation-Maximization$) \cite{anagnostopoulos2014scaling} y los modelos bayesianos ($Naive$ $Bayes$ y $Bayesian$ $Linear$ $Regression$) \cite{mavai2014survey}. Otras técnicas populares incluyen modelos matemáticos que intentan minimizar errores o ajustar una función basados en conocimiento obtenido a partir de datos de entrenamiento, como por ejemplo, Redes Neuronales Artificiales \cite{nelwamondo2007missing} y Máquinas de Soporte Vectorial \cite{hsu2003practical}. De todos estos algoritmos, los primeros son los que más se ajustan al problema planteado en este proyecto, dado que dependen directamente de medidas de similitud.\\
En términos generales, cuando se habla de análisis de documentos de texto a gran escala, la literatura se enfoca en dos tipos de métodos: los lingüísticos y los estadísticos \cite{srivastava2009text}. \\
En los métodos lingüísticos, la idea es manejar el texto basado en procesamiento de lenguaje natural, tomando en cuenta la representación semántica y las relaciones que se expresan entre las palabras en un modelo de lenguaje \cite{srivastava2009text}. De esta manera, diversos autores han incorporado el factor semántico al momento de comparar documentos, siendo necesaria la integración de una fuente externa de conocimiento como Wikipedia o técnicas ontológicas \cite{seifzadeh2015short}. En \cite{lazar2014improving, devraj2015twitter, martinez2014analysis} se hace uso de $WordNet$, una de las bases de datos léxicas del idioma inglés más utilizadas para determinar similitud semántica entre documentos. En estos estudios, la similitud entre palabras está determinada por el grado de traslape en los significados (dado que una palabra puede tener múltiple semántica) y la distancia entre los dos términos al ser representados en un grafo de hiperónimos (Por ejemplo, la palabra “animal” y la palabra “perro” están relacionadas debido a que en el grafo taxonómico una contiene a la otra) \cite{ devraj2015twitter}. Además de $WordNet$, otros autores han utilizado el repositorio $Google$ $tri-grams$ como tesauro del idioma inglés para similitud semántica \cite{davison2014p, soto2015similarity}.\\
A pesar de que estos métodos lingüísticos pueden llegar a formar representaciones más expresivas del texto, también agregan más complejidad al proceso debido a la dificultad que supone la construcción de un modelo semántico y a la dependencia con el contexto específico de cada conjunto de datos \cite{srivastava2009text}. Este trabajo se enfoca, por lo tanto, en métodos estadísticos que involucran la representación matemática del texto sin tomar en cuenta la semántica ni las propiedades del lenguaje \cite{srivastava2009text}. El proceso general consiste en elegir una técnica para la representación de dos documentos de texto y luego aplicar una función o métrica sobre ambas representaciones para calcular la similitud. \\
El vector de palabras es la técnica de representación más común, utilizada en la mayoría de la literatura consultada \cite{aggarwal2015data,soto2015similarity,kumaran2004text,xu2012combining,srivastava2009text, lazar2014improving}. Ésta consiste en representar cada documento de texto como un vector, donde cada entrada corresponde a un término y  el valor de la entrada es la frecuencia de ese término en el documento \cite{aggarwal2015data}. Otra técnica común de representación es la denominada $TF-IDF$ utilizada en \cite{araki2014annotation,soto2015similarity}, en la cual se le asignan pesos a los términos de un vector de modo que se le resta relevancia a palabras que aparecen con mucha frecuencia en el conjunto de datos, y se le da importancia a aquellas con pocas ocurrencias.\\
En \cite{lazar2014improving,bae2014computing} se hace uso de LDA, un modelo probabilístico generativo que se basa en dos conceptos principales: 1) un mismo documento de texto puede tener muchos temas latentes y 2) cada tema está formado por una distribución de palabras. De esta forma, en lugar de un vector de palabras cuyo tamaño depende del total de términos distintos en todo el conjunto de datos, un documento puede ser representado por un vector de temas distintos con las probabilidades de pertenecer a cada uno. Con respecto al vector de palabras, la representación LDA logra reducción dimensional, considera co-ocurrencia de palabras y sinónimos entre documentos (incorporando así el elemento semántico) y toma en cuenta todo el conjunto de datos al utilizar todas las categorías \cite{bae2014computing}.\\
Con respecto a las métricas de similitud de texto, la literatura es bastante extensa, siendo la similitud de Coseno una de las técnicas más utilizadas, tal como en \cite{liebman2016capturing,soto2015similarity}. En \cite{bae2014computing}, los autores combinan la representación LDA con la función Coseno para calcular la similitud entre publicaciones basadas en el $abstract$, el título y los autores. Otras medidas utilizadas tanto para clasificación como para agrupamiento de documentos de texto, incluyen la similitud de $Jaccard$ \cite{liebman2016capturing,soto2015similarity} y otras que se basan en comparación de hileras texto como la distancia $levenshtein$ \cite{gong2009matching, treeratpituk2012name} y la medida $longest$ $common$ $subsequence$ \cite{islam2008semantic, soto2015similarity}.\\
Huang \cite{huang2008similarity} hace uso de la divergencia KL para determinar la distancia entre dos documentos, suponiendo que la representación está basada en distribuciones de probabilidad. Esta métrica también es conocida como entropía relativa y, al no ser simétrica, se realiza un cálculo de promedio ponderado para obtener el valor final. Estudios realizados en \cite{huang2008similarity, metzler2007similarity}, muestran que la divergencia KL supera considerablemente a la distancia coseno, la similitud $Jaccard$ y la distancia euclidiana al momento de calcular el grado de pureza y entropía sobre ciertos conjuntos de datos de tipo texto.
En las siguientes secciones se define la hipótesis de investigación, las métricas a realizar y la justificación de la propuesta del proyecto.

\section{Hipótesis}
Considerando la definición del problema y la propuesta de proyecto descrita anteriormente, se plantea la siguiente hipótesis:\\\\
\textbf{En la imputación de valores faltantes basada en clasificación de atributos de texto, un algoritmo agregado que utilice técnicas de representación de documentos y medidas de similitud de texto: LDA y divergencia KL, obtiene una exactitud mayor que el mismo algoritmo agregado cuando utiliza métodos tradicionales (vector de palabras, similitud \textit{Jaccard} y distancia Coseno).}


\section{Métricas}\label{metrics-section}
En esta sección se detallan las métricas a considerar para evaluar los experimentos de este proyecto, descritas en \cite{wang2016non}, las cuales corresponden a la exactitud, precisión y sensibilidad. De esta forma, si se tiene un conjunto de datos $D$, donde $X$ es un subconjunto de $D$ que contiene aquellos registros en los cuales el algoritmo imputó los datos correctamente, $I_{c}$ contiene las instancias en las cuales el algoritmo imputó el valor $c$ y $R_{c}$ es el conjunto de registros en los cuales el valor faltante realmente corresponde al valor $c$, entonces:
\begin{itemize}
\item [1.] La \textbf{exactitud} determina el porcentaje de aciertos en un experimento tomando en cuenta el total de la población, usando la siguiente fórmula:
\begin{equation}
\label{equation-precision}
exactitud = \frac{\mid X \mid}{\mid D \mid} 
\end{equation}

\item [2.] La \textbf{precisión} en un determinado experimento y para una determinada etiqueta o clase $c$, representa la proporción de instancias de dicha clase correctamente clasificadas con respecto al total de instancias clasificadas bajo esa etiqueta por el algoritmo. La fórmula utilizada es la siguiente:
\begin{equation}
\label{equation-accuracy}
precision = \frac{\mid I_{c} \cap R_{c} \mid}{\mid I_{c} \mid}
\end{equation}

\item [3.] Y la \textbf{sensibilidad (\textit{recall})} en un determinado experimento y para una determinada etiqueta o clase $c$, corresponde a la proporción de instancias de dicha clase correctamente clasificados sobre el total de instancias donde el valor correcto es esa clase:
\begin{equation}
\label{equation-recall}
sensibilidad = \frac{\mid I_{c} \cap R_{c} \mid}{\mid R_{c} \mid}
\end{equation}
\end{itemize}
\section{Justificación del Proyecto}
Basado en las secciones anteriores, es evidente que el problema de los valores faltantes ha sido atacado extensamente desde diversos ámbitos. Sin embargo, no existen publicaciones en las que dicho problema se solucione explícitamente con la imputación de valores basada en clasificación atributos de texto. Tampoco se encontraron estudios que exploren los conceptos de métodos agregados aplicados a técnicas de representación y medidas de similitud de texto, ya que los mismos generalmente son trabajados a nivel de algoritmo y no de métrica. En esta misma dirección, las principales medidas de similitud a estudiar (LDA y divergencia KL) no se utilizan muy comúnmente en la literatura para comparación de documentos de texto, a pesar de que sus propiedades estadísticas podrían llegar a obtener mejores resultados al momento de ser aplicadas en un algoritmo de clasificación. \\
El nuevo método a proponer no intenta encontrar una solución para un problema o conjunto de datos en específico, sino que puede llegar a ser aplicado sobre cualquier conjunto de datos que esté compuesto por atributos de textos cortos y un atributo categórico en el que existan valores faltantes. El único requisito es que haya una relación de dependencia entre el atributo de tipo texto observado o completo y el atributo categórico. \\
Por último, el enfoque de este proyecto corresponde al análisis léxico y estructural de atributos de texto, sin tomar en cuenta análisis semántico dependiente de tesauros o grafos de hiperónimos. Esto ayuda a evitar que la solución dependa de un lenguaje o un contexto específico. El factor semántico introducido por la representación LDA también evita estas dependencias al adaptarse al dominio categórico de los valores faltantes en cada conjunto de documentos específico.
