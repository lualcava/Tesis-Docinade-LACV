% $Log: abstract.tex,v $
Actualmente, muchas bases de datos alrededor del mundo sufren un problema general de valores faltantes, el cual es causado por diversas razones que van desde fallos de \textit{hardware} hasta valores no ingresados por los usuarios. La idea de imputación de datos, en términos generales, consiste en utilizar algún método que permita encontrar valores plausibles para aquellos atributos en donde el valor no existe, utilizando los valores que sí existen. Cuando los valores existentes son solamente de tipo texto, el problema puede verse como uno de algoritmos de clasificación, donde se deben organizar los documentos de texto en diferentes categorías (valores faltantes a imputar). Esto implica también el problema de determinar computacionalmente qué tan similar es un texto a otro. La literatura existente sobre métodos para resolver este problema es muy extensa, sin embargo, los métodos estadísticos han mostrado resultados muy favorables en los últimos 25 años en el campo de la minería de texto \cite{srivastava2009text}. Estos métodos son aquellos que implican la representación de documentos mediante vectores de palabras y la utilización de medidas de distancia entre vectores, tales como Coseno o \textit{Jaccard}. Este proyecto se enfoca en la evaluación de medidas de similitud no tradicionales como la Asignación de Dirichlet Latente y la Divergencia Kullback-Leibler, los cuales han mostrado buenos resultados en clasificación de documentos haciendo uso del concepto de similitud entre distribuciones de probabilidad. Así mismo, se pretende combinar dichas métricas mediante métodos agregados con el fin de proponer un nuevo algoritmo de clasificación de texto para, eventualmente, imputar valores faltantes.

\subsubsection{Abstract}
\begin{hyphenrules}{nohyphenation}
Nowadays, there is a general problem of missing values in databases around the world, which is caused by several reasons going from hardware malfunctions to non-mandatory fields in forms. Data imputation, generally speaking, is defined as the use of methods to find plausible values for those ones that are missing by using the values that are actually there. If the existing values consist on text only, then the problem can be seen as a classification algorithms problem where text documents should be organized within categories representing the plausible missing values. It also implies the problem of calculating how similar is a text value with respect to another. Existing literature about solving this kind of problems is extensive, however, during the last 25 years the statistical methods have achieved good results in many areas of text mining \cite{srivastava2009text}. Traditional statistical methods involve the representation of documents using vectors of words and metrics to calculate vectors distances such as Cosine and Jaccard similarity. This project is focused on the evaluation of non-traditional similarity metrics such as Latent Dirichlet Allocation (LDA) and Kullback-Leibler Divergence that have shown good results in document classification by using the concept of probability distributions similarity. It also intends to combine the metrics through ensemble methods in order to propose a new text classification algorithm for missing value imputation.
\end{hyphenrules}


